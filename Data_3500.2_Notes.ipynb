{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ***DATA 3500*** *: Python 2*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction to pandas and Intermediate Python**\n",
    "  - We will introduce one of the most widely used lilbraries today and look at some of the basic features.\n",
    "  - We will continue to look at more advanced uses of Python.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas, imported with **import pandas as pd** adopts many coding idioms from Numpy, but the biggest difference is that pandas is designed for working with tabular or heterogeneous data. Numpy, by contrast, is best suited for working with homogeneous numerical array data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Introduction to pandas Data Structures**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started with pandas, you will need to understand its two primary data structures: **Series** and **DataFrame**. These two data structures provide a solid, easy-to-use basis for most data science applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Series**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A series is a one-dimenstional array-like object containing a sequence of values (of similar types to numpy types) and an associated array of data labels, called its **index**. The simplest series is formed from only an array of data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    7\n",
       "2   -5\n",
       "3    2\n",
       "dtype: int64"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remember to import your libraries.\n",
    "# The number you see on the left is the index and the value is on the right.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "obj = pd.Series([4, 7, -5, 2])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Often is it desirable to create a series with an index for each data point.\n",
    "\n",
    "obj2 = pd.Series([4, 2, -5, 3], index=['d', 'b', 'a', 'c'])\n",
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use index values to select observations.\n",
    "\n",
    "obj2[['c', 'a', 'd']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use numpy-like operations such as filtering, multiplication, or applying math functions.\n",
    "\n",
    "# filtering\n",
    "print(obj2[obj2 > 0])\n",
    "\n",
    "# multiplication\n",
    "print(obj2 * 2)\n",
    "\n",
    "# math functions\n",
    "import numpy as np\n",
    "print(np.exp(obj2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dictionaries**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often just referred to as **dict**, it is one of the most important built-in Python data structures. It is a flexibly sized collection of **key-value** pairs, where **key** and **value** are Python objects. One approach to creating one is to use curly braces **{}** and colons **:** to separate **keys** and **values**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with a simple dictionary\n",
    "# {key:value, ...}\n",
    "\n",
    "d1 = {'a' : 'some value', 'b': [1, 2, 3, 4]}\n",
    "d1['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How we accomplish something with a list.\n",
    "\n",
    "pop = [30.55, 2.77, 39.21]\n",
    "countries = ['afghanistan', 'albania', 'algeria']\n",
    "alb = countries.index('albania')\n",
    "pop[alb]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the dictionary to our list populations and countries\n",
    "# Set this up with key:value pairs.\n",
    "\n",
    "world = {'afghanistan':30.55, 'albania':2.77, 'algeria':39.21}\n",
    "world['albania'] # pass the key in square brackets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Try problem #1**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can access, insert, or set elements using the same syntax as for accessing elements of a list.\n",
    "# In the below example, 7 becomes the key and 'an integer' becomes the value.\n",
    "\n",
    "# insert an element\n",
    "d1[7] = 'an integer'\n",
    "print(d1)\n",
    "\n",
    "# access an element\n",
    "print(d1[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also check to see if a dict contains a key.\n",
    "\n",
    "'b' in d1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can delete values with del or the pop method (which returns a value and deletes the key)\n",
    "\n",
    "# del\n",
    "print(d1)\n",
    "d1[5] = 'some value'\n",
    "print(d1)\n",
    "d1['dummy'] = 'another value'\n",
    "print(d1)\n",
    "del d1[5]\n",
    "print(d1)\n",
    "\n",
    "# pop\n",
    "ret = d1.pop('dummy')\n",
    "print(ret)\n",
    "print(d1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Try problem #2**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Try problem #3**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Try problem #4**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Using Dictionaries within pandas**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you have data in a dictionary, we can create a Series from that.\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "sdata = {'Ohio': 35000, 'Texas':71000, 'Oregon':16000, 'Utah':5000}\n",
    "obj3 = pd.Series(sdata)\n",
    "\n",
    "obj3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The above keys are in the order of the dictionary.\n",
    "# We can specify any order we want.\n",
    "\n",
    "states = ['California', 'Ohio', 'Oregon', 'Texas']\n",
    "obj4 = pd.Series(sdata, index=states)\n",
    "\n",
    "obj4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we have the values from sdata in the appropriate locations, but because no value exists for 'California' it appears as **NaN** (not a number), which is considered in pandas to mark missing or NA values. Since 'Utah' was not included in the **states** list, it is excluded from the resulting object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use isnull and notnull functions from pandas to detect missing data.\n",
    "# Notice that they give you opposite results.\n",
    "\n",
    "print(pd.isnull(obj4))\n",
    "print(pd.notnull(obj4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **DataFrame**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A DataFrame represents a rectangular table of data and contains an ordered collection of columns, each of which can be a different value type (numeric, string, boolean, etc...). The DataFrame has both a row and column index; it can be thought of as a dict of Series all sharing the same index. The data is stored as one or more two-dimensional blocks rather than a list, dict, or some other collection one-dimensional arrays.\n",
    "\n",
    "There are many ways to create a DataFrame.\n",
    "\n",
    "One way to think of a DataFrame is like an excel file with rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a DataFrame from a dict of equal-length lists or numpy arrays.\n",
    "\n",
    "data = {'state': ['Ohio', 'Ohio', 'Ohio', 'Nevada', 'Nevada', 'Nevada'],\n",
    "        'year': [2000, 2001, 2002, 2001, 2002, 2004],\n",
    "        'pop': [1.5, 1.7, 3.6, 2.4, 2.9, 3.2]}\n",
    "frame = pd.DataFrame(data)\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we have a large dataset that we do not want to type out?\n",
    "# We can import data as well.\n",
    "\n",
    "brics = pd.read_csv('Data/country.csv')\n",
    "brics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# The row labels are seen as a column which isn't correct.\n",
    "# We can correct this by telling pandas that the first column contains row indexes.\n",
    "\n",
    "brics = pd.read_csv('Data/country.csv', index_col = 0)\n",
    "brics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Try problem #5**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Try problem #6**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For large DataFrames, the head method selects the first 5 rows.\n",
    "\n",
    "frame.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The tail method selects the last 5 rows.\n",
    "\n",
    "frame.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The sample method selects n random rows.\n",
    "\n",
    "frame.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you can specify a sequence of columns and the DataFrame will be arranged in that order.\n",
    "\n",
    "pd.DataFrame(data, columns = ['year', 'state', 'pop'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you pass a column that is not in the dict/data, it will appear with missing values.\n",
    "\n",
    "frame2 = pd.DataFrame(data, columns = ['year', 'state', 'pop', 'debt'])\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets recreate frame2 with specific index values\n",
    "\n",
    "frame2 = pd.DataFrame(data, columns = ['year', 'state', 'pop', 'debt'],\n",
    "                      index = ['one', 'two', 'three', 'four', 'five', 'six'])\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A column in a DataFrame can be retrieved two ways.\n",
    "\n",
    "frame2['state']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# or...\n",
    "\n",
    "frame2.state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can retrieve rows by position or name with the special loc atribute.\n",
    "\n",
    "frame2.loc['three']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns can be modified by assignment.\n",
    "# For example, the empty 'debt' column.\n",
    "\n",
    "frame2['debt'] = 16.5\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can assign different values to each observation as well.\n",
    "# We already imported numpy above.\n",
    "\n",
    "frame2['debt'] = np.arange(6)\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning a column that does not exist will create a new column.\n",
    "# Below create a new column called eastern and assign True to each observation of Ohio.\n",
    "\n",
    "frame2['eastern'] = (frame2['state'] == 'Ohio')\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can remove this column with del.\n",
    "\n",
    "del frame2['eastern']\n",
    "frame2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Another common form of data is the nested dict of dicts.\n",
    "\n",
    "pop = {'Nevada': {2001: 2.4, 2002: 2.9},\n",
    "       'Ohio': {2000: 1.5, 2001: 1.7, 2002: 3.6}}\n",
    "frame3 = pd.DataFrame(pop)\n",
    "frame3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can sort by index.\n",
    "# This is not a permanent sort though.\n",
    "\n",
    "print(frame3.sort_index())\n",
    "print(frame3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use inplace=True to make it permanent.\n",
    "\n",
    "frame3.sort_index(inplace=True)\n",
    "frame3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "frame3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can transpose the DataFrame (swap rows and columns) as well.\n",
    "\n",
    "frame3.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can reindex which creates a new object with a new index.\n",
    "\n",
    "obj = pd.Series([4.5, 7.2, -5.3, 3.6], index=['d', 'b', 'a', 'c'])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling reindex rearranges the new index.\n",
    "# Missing values are introduced in any index values were not already present.\n",
    "\n",
    "obj2 = obj.reindex(['a', 'b', 'c', 'd', 'e'])\n",
    "obj2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If data is ordered, it may be desireable to do some interpolation or fill in missing values.\n",
    "# We can accomplish this with options such a ffill which forward fills values.\n",
    "\n",
    "obj3 = pd.Series(['blue', 'purple', 'yellow'], index = [0, 3, 4])\n",
    "obj3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj3.reindex(range(8), method='ffill')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Dropping Entries from an Axis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dropping one or more entries from an axis is easy if you already have an index array or list without those entries. The drop method will reutrn a new object with the indicated value or values deleted from an axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up a Series to work with.\n",
    "# Make the series fill with floats.\n",
    "\n",
    "obj = pd.Series(np.arange(5.), index=['a', 'b', 'c', 'd', 'e'])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop row c.\n",
    "\n",
    "new_obj = obj.drop('c')\n",
    "new_obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop rows c and d.\n",
    "\n",
    "obj.drop(['c', 'd'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a DataFrame, we can delete values from either axis.\n",
    "# Create a new DataFrame to work with.\n",
    "\n",
    "data = pd.DataFrame(np.arange(16).reshape((4,4)),\n",
    "                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n",
    "                    columns = ['one', 'two', 'three', 'four'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calling drop on a DataFrame will drop values from the row labels.\n",
    "\n",
    "data.drop(['Colorado', 'Ohio'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can drop values from the columns by passing axis = 1 or axis = 'columns'.\n",
    "\n",
    "data.drop('two', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the axis = 'columns' option.\n",
    "\n",
    "data.drop(['two', 'four'], axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want this to be a permanent change, we must use inplace=True.\n",
    "# Be careful when using inplace, it destroys the original data and replaces it with the new.\n",
    "\n",
    "print(obj)\n",
    "\n",
    "obj.drop('d', inplace=True)\n",
    "obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Indexing, Selecting, and Filtering**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Series indexing (**obj[...]**) works analogously to numpy array indexing, except you can use the Series index values instead of only integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets move on to working with DataFrames.\n",
    "\n",
    "data = pd.DataFrame(np.arange(16).reshape((4,4)),\n",
    "                    index=['Ohio', 'Colorado', 'Utah', 'New York'],\n",
    "                    columns = ['one', 'two', 'three', 'four'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select column 'two'.\n",
    "# This is no longer a DataFrame though.\n",
    "\n",
    "data['two']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to keep this as a DataFrame, we must use [[]].\n",
    "\n",
    "data[['two']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select columns 'three' and 'one'.\n",
    "# And we can again keep this as a DataFrame with [[]].\n",
    "\n",
    "data[['three', 'one']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select the first two rows of data and keep all columns.\n",
    "\n",
    "data[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select only those rows where the column 'three' is greater than 5.\n",
    "\n",
    "data[data['three'] > 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can produce a boolean DataFrame by scalar comparison.\n",
    "\n",
    "data < 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can take advantage of this to replace only specific values.\n",
    "\n",
    "data[data < 5] = 0\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Selection with loc and iloc**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For DataFrame label-indexing on the rows, the special indexing operators for **loc** and **iloc** are introduced. They enable you to select a subset of the rows and columns from a DataFrame with numpy-like notation using either axis labels (**loc**) or integers (**iloc**)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a single row by label with loc.\n",
    "\n",
    "data.loc['Colorado']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We can maintain the DataFrame with [[]].\n",
    "\n",
    "data.loc[['Colorado']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can select multiple rows and maintain a DataFrame.\n",
    "\n",
    "data.loc[['Ohio', 'Utah']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can extend this to only keep specific rows as well.\n",
    "\n",
    "data.loc[['Ohio', 'Utah'], ['one', 'three']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finally, we can keep all rows and only some columns.\n",
    "\n",
    "data.loc[:, ['one', 'three']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap:\n",
    "- Square brackets\n",
    "    - Column access data[['row', 'column]]\n",
    "    - Row access only through slicing data[1:4]\n",
    "- loc (label-based)\n",
    "    - Row access data.loc[['row labels']]\n",
    "    - Column access data.loc[:, ['row labels', 'column labels']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a selection using integers and iloc.\n",
    "# Select row location 2 (3rd row) and columns locations 3 (4th column), \n",
    "# 0 (1st column), and 1 (2nd column). \n",
    "\n",
    "data.iloc[2, [3, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select all of row location 2.\n",
    "\n",
    "data.iloc[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select row location 1 and 2 and column locations 3, 0, and 1.\n",
    "# Double brackets results in a DataFrame.\n",
    "\n",
    "data.iloc[[1, 2], [3, 0, 1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can index with slices in addition to single labels or lists of labels.\n",
    "# Select all rows through 'Utah' and select column 'two'\n",
    "\n",
    "data.loc[:'Utah', 'two']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select all rows and column index 0 through 2.\n",
    "# Within this set, select only rows where 'three' > 5.\n",
    "\n",
    "data.iloc[:, :3][data.three > 5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Try problem #7**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Try problem #8**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Try Problem #9**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Loops**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Loops, such as while loops and for loops, are somewhat similar to our use of if, else, and elif statements. We do something until a condition is met. With the if, else, elif statements, Python will go through the code one time until it meets the condition and then move on to the next set of code. That is not the case with loops. A while loop will continue to execute code as long as a condition is true."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider a simple while loop.\n",
    "# Lets keep adding numbers together until they reach 100 or more.\n",
    "# If we start with 10, it becomes (10 + 10), then (20 + 20), then (40 + 40), and finally (80 + 80)\n",
    "\n",
    "number = 10\n",
    "\n",
    "while number < 100:\n",
    "    number = number + number\n",
    "    print(number)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Try Problem #10**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We now look at for loops which have the setup: for each variable in a sequence, execute code. \n",
    "# Let us look at the fam list and print each item out individually.\n",
    "\n",
    "fam = [1.73, 1.68, 1.71, 1.89]\n",
    "print(fam[0])\n",
    "print(fam[1])\n",
    "print(fam[2])\n",
    "print(fam[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also do this with a for loop.\n",
    "# height is arbitrary, we can call it whatever we want.\n",
    "\n",
    "for height in fam:\n",
    "    print(height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can loop over a string as well.\n",
    "# This will iterate over every character in a string.\n",
    "\n",
    "for c in 'family':\n",
    "    print(c.capitalize())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Try Problem #11**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can loop over a dictionary as well.\n",
    "# Print each key and value pair.\n",
    "\n",
    "world = {'afganhistan': 30.55,\n",
    "       'albania': 2.77,\n",
    "       'algeria': 39.21}\n",
    "\n",
    "for k, v in world.items():\n",
    "    print(k + ' population is ' + str(v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can loop over a DataFrame as well.\n",
    "# This is the most widely used setup.\n",
    "\n",
    "brics = pd.read_csv('Data/country.csv', index_col = 0)\n",
    "brics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a for loop to print each row.\n",
    "# We must specify that we want to iterate over each row.\n",
    "\n",
    "for label, row in brics.iterrows():\n",
    "    print(label)\n",
    "    print(row)\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can print the label and capital together as an example.\n",
    "\n",
    "for l, r in brics.iterrows():\n",
    "    print(l + ': ' + r['capital'] + ', ' + r['country'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "brics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a row to the DF that contains the number of letters each country.\n",
    "\n",
    "for l, r in brics.iterrows():\n",
    "    brics.loc[l, 'name_length'] = len(r['country'])\n",
    "brics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also use .apply() to apply our function to each row.\n",
    "# This is more efficient code and easier to read.\n",
    "\n",
    "#brics['name_failed'] = len(brics['country'])\n",
    "brics['name_length_apply'] = brics['country'].apply(len)\n",
    "brics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Try Problem #12**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Try Problem #13**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **If, Elif, and Else Statements**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using if, elif, or else statements.\n",
    "# These are known as conditional statements.\n",
    "\n",
    "z = 6\n",
    "\n",
    "if z % 2 == 0:\n",
    "    print('z is even')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can expand this statement.\n",
    "\n",
    "z = 6\n",
    "\n",
    "if z % 2 == 0:\n",
    "    print('checking value: ' + str(z))\n",
    "    print('z is even')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we want something to happen when z is odd?\n",
    "# We can use an else statement.\n",
    "\n",
    "z = 7\n",
    "\n",
    "if z % 2 == 0:\n",
    "    print('z is even')\n",
    "else:\n",
    "    print('z is odd')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What if we want even more output options?\n",
    "# We can use an elif statement as many times as we want.\n",
    "# In this case, the else statement is a catch-all at the end.\n",
    "\n",
    "z = 5\n",
    "\n",
    "if z % 2 == 0:\n",
    "    print('z is divisible by 2')\n",
    "elif z % 3 == 0:\n",
    "    print('z is divisible by 3')\n",
    "else:\n",
    "    print('z is neither divisible by 2 nor by 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What happens if z = 6 and the if and elif statements are true?\n",
    "# As soon as we get a True outcome, the code stops.\n",
    "# We never get to execute the elif statement.\n",
    "\n",
    "z = 6\n",
    "\n",
    "if z % 2 == 0:\n",
    "    print('z is divisible by 2')\n",
    "elif z % 3 == 0:\n",
    "    print('z is divisible by 3')\n",
    "else:\n",
    "    print('z is neither divisible by 2 nor by 3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Try Problem #14**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **List, Set, and Dict Comprehensions**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List comprehensions are one of the most used Python language features. They allow you to concisely form a new list by filtering the elements of a collection, transforming the elements, and passing the filter in one concise expression. They take the basic form: \n",
    "\n",
    "**[expr for val in collection if condition]**\n",
    "\n",
    "This is equivalent to the following for loop:\n",
    "\n",
    "**result = []**\n",
    "\n",
    "**for val in collection:**\n",
    "\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;**if condition:**\n",
    " \n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;**result.append(expr)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a list of numbers and we want to create a new list.\n",
    "# The new list will have the original numbers with 1 added to them.\n",
    "# We could accomplish this with a for loop, but list comprehension is faster.\n",
    "\n",
    "nums_list = [5, 10, 15, 20, 25]\n",
    "\n",
    "new_nums = [x + 1 for x in nums_list]\n",
    "print(new_nums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use a list comprehension with any iterable.\n",
    "\n",
    "result = [num for num in range(11)]\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The filter condition can be omitted, leaving only the expression. \n",
    "# For each observation in string, make it uppercase if it is longer than 2 letters.\n",
    "\n",
    "strings = ['a', 'as', 'bat', 'car', 'dove', 'python', 'an']\n",
    "\n",
    "[x.upper() for x in strings if len(x) > 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nested list comprehensions are a bit hard to understand. The for parts of the list comprehension are arranged according to the order of nesting, and any filter condition is put at the end as before. Here is another example where we 'flatten' a list of tuples of integers into a simple list of integers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also include conditionals in comprehensions.\n",
    "# Remember that % is the modulo operator.\n",
    "\n",
    "[num ** 2 for num in range(10) if num % 2 == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For an even integer, output its square.\n",
    "\n",
    "[num ** 2 if num % 2 == 0 else -99 for num in range(10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Try Problem #15**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Arithmetic and Data Alignment**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An important pandas feature for some applications is the behavior of arithmetic between objects with different indexes. When you are adding together objects, if any index pairs are not the same, the respective index in the result will be the union of the index pairs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consider an example with a Series.\n",
    "\n",
    "s1 = pd.Series([7.3, -2.5, 3.4, 1.5], index=['a', 'c', 'd', 'e'])\n",
    "s2 = pd.Series([-2.1, 3.6, -1.5, 4, 3.1], index=['a', 'c', 'e', 'f', 'g'])\n",
    "print(s1)\n",
    "print(s2)\n",
    "print('')\n",
    "s1 + s2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the case of a DataFrame, alignment is perfomed on both the rows and columns.\n",
    "\n",
    "df1 = pd.DataFrame(np.arange(9.).reshape((3,3)), columns=list('bcd'), index=['Ohio', 'Texas', 'Colorado'])\n",
    "df2 = pd.DataFrame(np.arange(12.).reshape((4,3)), columns=list('bde'), index=['Utah', 'Ohio', 'Texas', 'Oregon'])\n",
    "print(df1)\n",
    "print(df2)\n",
    "print('')\n",
    "df1 + df2 \n",
    "# Because c and e are not in both DFs, they appear as NaNs.\n",
    "# The same holds true for rows not found in both original DFs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Arithmetic with fill values is an option.\n",
    "# We will create miss matched DFs with an additional missing value.\n",
    "\n",
    "df1 = pd.DataFrame(np.arange(12.).reshape((3, 4)), columns=list('abcd'))\n",
    "df2 = pd.DataFrame(np.arange(20.).reshape((4, 5)), columns=list('abcde'))\n",
    "df2.loc[1, 'b'] = np.nan # Adding one extra random missing value to df2.\n",
    "print(df1)\n",
    "print(df2)\n",
    "print('')\n",
    "df1 + df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the add method on df1 and pass df2 and an argument to fill_value.\n",
    "# This will fill the NaN values with values from the single df.\n",
    "\n",
    "df1.add(df2, fill_value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Sorting and Ranking**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sorting a dataset by some criterion is another important built-in operation. There are a few different ways to sort Series and DataFrames which we will explore here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obj = pd.Series(range(4), index=['d', 'a', 'b', 'c'])\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the series by index values.\n",
    "\n",
    "obj.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With a DataFrame we can sort by index on either axis.\n",
    "\n",
    "frame = pd.DataFrame(np.arange(8).reshape((2, 4)),\n",
    "                     index=['tree', 'open'],\n",
    "                     columns=['d', 'a', 'b', 'c'])\n",
    "print(frame)\n",
    "frame.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by the column values now.\n",
    "\n",
    "frame.sort_index(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also sort in descending order.\n",
    "\n",
    "frame.sort_index(axis=1, ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Missing values will be sorted to the end of the Series.\n",
    "\n",
    "obj = pd.Series([4, np.nan, 7, np.nan, -3, 2])\n",
    "obj.sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can sort DataFrames by the data in one or more columns as the sort keys.\n",
    "# We must pass one or more column names to the by option of sort_values.\n",
    "\n",
    "frame = pd.DataFrame({'b': [4, 7, -3, 2], 'a': [0, 1, 0, 1]})\n",
    "frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by column b.\n",
    "\n",
    "frame.sort_values(by='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by columns a and b.\n",
    "# This will first sort all values by a and then within value of a, sort by values of b.\n",
    "\n",
    "frame.sort_values(by=['a', 'b'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Summarizing and Descriptive Statistics**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pandas objects are equipped with a set of common mathematical and statistical methods. Most of these fall into the category of *reductions* or *summary statistics*, mothods that extract a single value (like the sum or mean) from a Series or a Series of values from the rows or columns of a DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at a DataFrame with missing values.\n",
    "\n",
    "df = pd.DataFrame([[1.4, np.nan], [7.1, -4.5], [np.nan, np.nan], [0.75, -1.3]],\n",
    "                 index=['a', 'b', 'c', 'd'], columns=['one', 'two'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of a column.\n",
    "\n",
    "df.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the sum of across the columns now (ie. sum down a row).\n",
    "\n",
    "df.sum(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NA values are excluded here unless we disable this option.\n",
    "# Cannot have a mean value with an NA value if we do not exclude it from the calculation.\n",
    "# You notice axis=columns and axis=1 result in the same thing.\n",
    "\n",
    "df.mean(axis='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also calculate the cumulative sum.\n",
    "# These methods are known as accumulations.\n",
    "# This will sum down each column, adding values as it goes.\n",
    "\n",
    "print(df)\n",
    "df.cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One very useful method is describe.\n",
    "# This produces summary statistics in one output.\n",
    "\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Correlation and Covariance**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some summary statistics, like correlation and covariance, are computed from pairs of arguments. Let's consider some DataFrames of stock prices and volumes obtained from Yahoo! Finance using a new package, pandas-datareader. You might have to install this package using **pip install pandas_datareader**.\n",
    "\n",
    "We will use this package to download stock data directly from the internet with one line of code. One nice aspect of Python is how easy it is to obtain data from non-traditional databases such as Yahoo! Finance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download data for a few tickers and create price and volume DataFrames.\n",
    "\n",
    "import pandas_datareader.data as web\n",
    "\n",
    "all_data = {ticker: web.get_data_yahoo(ticker, start='2019-1-1', end='2020-2-8') for ticker in ['AAPL', 'IBM', 'MSFT', 'GOOG']}\n",
    "price = pd.DataFrame({ticker: data['Adj Close'] for ticker, data in all_data.items()})\n",
    "volume = pd.DataFrame({ticker: data['Volume'] for ticker, data in all_data.items()})\n",
    "\n",
    "price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can easily compute the percent change in prices, or returns, of our stocks.\n",
    "# The first value will always be NaN because percent change requires two prices, this periods and last periods. \n",
    "\n",
    "returns = price.pct_change()\n",
    "returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corr method computes the correlation of the overlapping non-NA values.\n",
    "# It requires two Series.\n",
    "\n",
    "returns['MSFT'].corr(returns['IBM'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If we want to return a full correlation matrix, we call corr() on the DataFrame.\n",
    "\n",
    "returns.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Unique Values, Value Counts, and Membership**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can display the unique values in a Series.\n",
    "\n",
    "obj = pd.Series(['c', 'a', 'd', 'a', 'a', 'b', 'b', 'c', 'c','e','e','e','e'])\n",
    "obj.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can also compute the value counts for each unique value.\n",
    "\n",
    "obj.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can utilize isin as a method of filtering datasets.\n",
    "\n",
    "obj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a file of observations that are 'b' or 'c'\n",
    "\n",
    "mask = obj.isin(['b', 'c'])\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can use this to subset obj.\n",
    "\n",
    "obj[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
